---
title: "Read-in and Data Processing"
output: html_document
date: "2025-01-14"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(wordVectors)

proj_path <- "C:/Users/Frances/Documents/Projects/Comp Linguistics/Projects/word_embed_test"
```

# 2024 NOW data

## Read-In

We start by reading in the small corpus sample from 2024. Our features of interest are "real-time," "language," "hired," and "translate." Each of these shows up multiple times even in the limited corpus we use. 


```{r read-in}
prep_word2vec(origin=paste0(proj_path,"/0-data"), destination="sample.txt", lowercase = T, bundle_ngrams=2)
```

## Take a Look

We create the word embedding model. 

```{r pressure, echo=FALSE}
#-------------------------
# reading in text file
#-------------------------
file_path <- "sample.txt"

# Open the file in binary mode
con <- file(file_path, "r")

# Read the entire file as a single string
long_string <- readChar(con, file.info(file_path)$size)

# Close the connection
close(con)

# fixing the "real time" term
fixed_string <- long_string %>% str_replace_all("real\\stime", "real_time")
realm <- str_extract_all(fixed_string, "real_time")
write(fixed_string, "sample-fixed.txt")

#-------------------------
# create word embedding
#-------------------------
if (!file.exists("sample_vectors.bin")) {
  model = train_word2vec("sample-fixed.txt","sample_vectors.bin",vectors=150,
                         threads=4,window=12,iter=5,negative_samples=0)} else model = read.vectors("C:/Users/Frances/Documents/Projects/Comp Linguistics/Projects/word_embed_test/1-scripts/sample_vectors.bin")
```

We can calculate or plot the proportion of times a word of interest shows up in the corpus.

## Exploration

We can see the top words associated with "interpreter." It seems like we'll need a more comprehensive database, since interpreter is most closely associated with baseball terms. In 2024, it doesn't seem to be an oft-used term in this NOW database sample.

```{r top-words-interpreter, options}
model %>%
  closest_to("interpreter")
```

The closest words to our features appear more reasonable.

```{r label, options}
features = c("real_time", "languages", "hired", "translate")
term_set = lapply(features, 
       function(feature) {
          nearest_words = model %>% closest_to(model[[feature]],20)
          nearest_words$word
        }) %>% unlist

subset = model[[term_set,average=F]]

subset %>%
  cosineDist(subset) %>% 
  as.dist %>%
  hclust %>%
  plot
```

## Analysis

Because we are interested in how close "speech" and "writing" are to the four features that potentially define "interpreter," we calculate the cosine similarity between the categories of interest and each of the features. We store this as a matrix. 

```{r model-features, options}
features = c("real_time", "languages", "hired", "translate")
instances = c("speech", "writing")


features_mat <- matrix(1:4, nrow=1)
colnames(features_mat) <- features

for(f in features) {
  features_mat[1,f] <- cosineSimilarity(model[["interpreter"]], model[[f]])
}

similarity_mat <- matrix(1:8, nrow=2, ncol=4)
rownames(similarity_mat) <- instances
colnames(similarity_mat) <- features

for(f in features) {
  for(i in instances) {
    similarity_mat[i,f] <- cosineSimilarity(model[[i]], model[[f]])
  }
}

similarity_mat
rowMeans(similarity_mat)

#model[str_detect(rownames(model), "real"),]
```

# Pre-trained Stanford GLOVE Data

There is one term which is duplicated and one that is NA, according to warning messages. So I take the first to get rid of that duplicate which probably doesn't matter and get rid of the NA term.

```{r read-in-glove, options}
library(data.table)
library(lsa)

# Specify the path to the GloVe file
glove_path <- paste0(proj_path,"/2-glove/glove.840B.300d.txt") 
# Load the GloVe embeddings
glove_wts <- data.table::fread(glove_path, quote = "", sep=" ", data.table = FALSE) 

# Removing NA and duplicate terms
glove_wts_mat <- glove_wts[!duplicated(glove_wts$V1) & !is.na(glove_wts$V1),]
rm(glove_wts)
rownames(glove_wts_mat)<- glove_wts_mat$V1
glove_wts_mat_fin <- glove_wts_mat[,-1] %>% as.matrix()
rm(glove_wts_mat)

# View the structure
head(glove_wts_mat_fin)
```


We can now try to apply the same analysis as before. It seems a little better: we can see that "real-time" is closer to speech than writing, which makes sense. However, there still seems to be concern that we're not getting the right feature words, or that there is some dimensionality missing. Maybe a more exploratory approach first would help? I'm thinking PCA/LDA or even looking at the closest words. 

```{r label, options}
features = c("real-time", "languages", "hired", "translate")

features_mat_glove <- matrix(1:4, nrow=1)
colnames(features_mat_glove) <- features

for(f in features) {
  features_mat_glove[1,f] <- cosine(glove_wts_mat_fin["interpreter",], glove_wts_mat_fin[f,])
}

similarity_mat_glove <- matrix(1:8, nrow=2, ncol=4)
rownames(similarity_mat_glove) <- instances
colnames(similarity_mat_glove) <- features

for(f in features) {
  for(i in instances) {
    similarity_mat_glove[i,f] <- cosine(glove_wts_mat_fin[i,], glove_wts_mat_fin[f,])
  }
}

features_mat_glove
similarity_mat_glove
rowMeans(similarity_mat_glove)
```